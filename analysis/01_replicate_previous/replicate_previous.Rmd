---
title: "Replicating The Linear Regression Models From Tomo's Study"
author: "Bin & Lizzy"
date: "6/25/2021"
output: 
  html_document:
    toc: true
    toc_float: true
    theme: spacelab
    toc_depth: 6
---


```{r setup, include=FALSE}
library(tidyverse)
library(here)
library(corrplot)

PREPOST_PATH <- here("data/prepost_cleaned.csv")
DATA_PATH <- here("data/processed/replicate.csv")

prepost <- read_csv(PREPOST_PATH)
df <- read_csv(DATA_PATH)
```

### Mean pre/posttest scores by condition

```{r, echo = T}
prepost %>%
  group_by(condition) %>%
  summarize(pk_pre = mean(PK_pre),
            pk_post = mean(PK_post),
            ck_pre = mean(CK_pre),
            ck_post = mean(CK_post),
            ckpk_pre = mean(CKPK_pre),
            ckpk_post = mean(CKPK_post))
```


### Correlation Matrix

```{r}
df %>%
  select(c(CK_post, PK_post, CKPK_pre, num_solved, inc_dia, inc_sym, hints, perc_hint_steps)) %>%
  cor() %>%
  round(3)
```

```{r}
df %>%
  select(c(CK_post, PK_post, CKPK_pre, num_solved, inc_dia, inc_sym, hints, perc_hint_steps)) %>%
  cor() %>%
  corrplot()
```


### Prediting Posttest CK and PK scores

*To test the effect of the intervention and its interaction with learners’ prior knowledge, we conducted two separate linear regressions, one with conceptual knowledge posttest scores and one with procedural knowledge posttest scores as dependent variables. In both models, condition (Diagram or No-Diagram), prior knowledge pretest score (combined CK and PK scores), and the interaction between the two served as predictors. Additionally, the number of problems solved in the ITS and grade level were included as covariates.*

##### Previous results

*In both models, there was no significant main effect of condition (CK: β = -0.20, t(78) = -0.28, p = .78, PK: β = -0.28, t(78) = -0.60, p = .55) and no significant interaction of condition and pretest scores (CK: β = .09, t(78) = .76, p = .45, PK: β = .03, t(79) = .39, p = .69).*

##### Results

```{r}
mod1 <- lm(CK_post ~ condition + CKPK_pre + condition:CKPK_pre + num_solved, data = df)
mod2 <- lm(PK_post ~ condition + CKPK_pre + condition:CKPK_pre + num_solved, data = df)
```
```{r, echo = T}
summary(mod1)
summary(mod2)
```

Here, `condition` and `condition:CKPK_pre` are not significant predictors of the posttest PK and CK scores at a significance level of 0.05, which matches with previous results. However, `condition` is a significant predictor of `PK_post` at the 0.10 significance level. Addtionally, the signs of the beta estimates for these predictors are the same as those from previous results (though need to know how `condition` was factored in the previous study).


### Factors that leads to efficient learning

*To examine whether learners in the Diagram condition showed efficient learning, we ran four separate linear regressions with each of the process measures [number of problems solved, average number of incorrect steps per symbolic step, average number of hints per symbolic step, and time used per symbolic step] as a dependent variable. In all four models, condition, pretest score, and their interaction were included as independent variables... we added the number of problems solved as a covariate to three of the four models (the ones in which it was not the dependent variable) because the number of problems solved was strongly/moderately correlated with each of the three other dependent variables.*

##### Previous results

*First, we found a main effect of pretest scores on the number of problems solved, β = 3.04, t(79) = 7.49, p < .01 ... This increase was steeper for students in the No-Diagram condition than the Diagram condition, β = -1.24, t(79) = -2.12, p = .04 ...*


*Regarding hint use and average time spent per step, we found a significant main effect of condition (hint use: β = - 0.71, t(78) = -3.08, p < .01; time per step: β = -12.18, t(78) =
-2.89, p < .01) but no significant interactions between condition and pretest score. There were no significant main nor interaction effects on the average number of incorrect attempts made per step.* 

##### Results

```{r}
mod1 <- lm(num_solved ~ condition + CKPK_pre + condition:CKPK_pre, data = df)
mod2 <- lm(inc_sym ~ condition + CKPK_pre + condition:CKPK_pre + num_solved, data = df)
mod3 <- lm(hints ~ condition + CKPK_pre + condition:CKPK_pre + num_solved, data = df)
mod4 <- lm(adj_avg_tps ~ condition + CKPK_pre + condition:CKPK_pre + num_solved, data = df)
```

```{r}
summary(mod1)
```
The pretest score is the only significant preditor for `num_solved`. Those who are in the interleaved condition seems to be benefiting more from higher pretest scores since the coefficient for the interaction terms is positive (though it is not significant). This matches with the previous study. 
```{r}
summary(mod2)
```
`num_solved` is the only significant predictor for the number of incorrect attempts, contrary to the previous study. This makes sense because the more problems the students solve, the more steps they encounter and the more chances they can make a mistake. 
```{r}
summary(mod3)
```
`condition` and the interaction term of `condition` and the pretest score are significant predictors for the number of hints used. In the previous study, only `condition` was significant.   
```{r}
summary(mod4)
```
`condition`, `num_solved`, and the interaction term between condition and pretest score are significant predictors of the adjusted average time spent per step. Only `condition` was significant in the previous study. 



### How does anticipatory diagrammatic selfexplanation scaffold in student performance?

*We ran three additional linear regressions with the same set of predictors of primary interest: pretest scores, the average number of incorrect attempts for each diagrammatic step, and the average time spent for each diagrammatic step. We did not include the average number of hints requested since only one student used hints for diagrammatic steps. We included grade level and the number of problems solved as covariates in order to keep the models consistent with other models presented earlier. The dependent variables for the three models were the average number of incorrect attempts for each symbolic step, the average time spent for each symbolic step, and the average number of hints requested for each symbolic step.*

##### Previous results

*When controlling for these other variables, the average number of incorrect attempts on diagram steps significantly predicted more incorrect attempts on symbolic steps (β = 6.17, t(35) = 2.50, p = .02) and more time spent on symbolic steps (β = 25.64, t(35) = 2.34, p = .03). There was also a significant association between more incorrect attempts on diagrammatic steps and lower hint use on symbolic steps (β = -1.46, t(35) = -2.32, p = .03). *

##### Results

Unable to get the time spent on diagrammic steps because there are no timestamps for the steps which students answers correctly on the first try. 

```{r}
# mod_incs_sym <- lm(inc ~ pre + incs_dia + time_dia + num_solved)
# mod_hint_sym <- lm(hint ~ pre + incs_dia + time_dia + num_solved)
# mod_time_sym <- lm(time ~ pre + incs_dia + time_dia + num_solved)
```
















